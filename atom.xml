<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>yutouwd</title>
  
  <subtitle>yutou&#39;s blog</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yutouwd.github.io/"/>
  <updated>2019-03-04T15:51:36.120Z</updated>
  <id>http://yutouwd.github.io/</id>
  
  <author>
    <name>yutouwd</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>kaldi在Windows下的使用</title>
    <link href="http://yutouwd.github.io/posts/3944650563/"/>
    <id>http://yutouwd.github.io/posts/3944650563/</id>
    <published>2019-02-26T12:49:11.000Z</published>
    <updated>2019-03-04T15:51:36.120Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>其实不是特别推荐在Windows下使用kaldi，因为在egs下所有的脚本都无法运行，我也是弄了很久才在Windows下配置好kaldi，都一度差点弃坑。就连官方也说<strong>There is no commitment to support Windows. The Windows port of Kaldi is targeted at experienced developers who want to program their own apps using the kaldi libraries and are able to do the troubleshooting on their own.</strong>就让我来把坑填平那么一点点吧🧐<br><a id="more"></a></p><h1 id="kaldi在Windows下的安装"><a href="#kaldi在Windows下的安装" class="headerlink" title="kaldi在Windows下的安装"></a>kaldi在Windows下的安装</h1><h2 id="工具准备"><a href="#工具准备" class="headerlink" title="工具准备"></a>工具准备</h2><ul><li>git</li><li>cmake</li><li>Visual Studio 2017</li></ul><p>vs2017要注意安装win8.1 SDK，如果已经安装了vs2017，也可以在上方的菜单栏中的工具-&gt;获取工具和功能中来查看是否有安装。git和cmake的安装没有什么特别的，就不做介绍了。</p><img src="/posts/3944650563/1.jpg"><h2 id="编译Openfst"><a href="#编译Openfst" class="headerlink" title="编译Openfst"></a>编译Openfst</h2><p>首先从github上将openfst clone下来。然后这里用cmake的方式来先编译出vs的工程文件，具体操作方法如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/kkm000/openfst.git</span><br><span class="line">cd openfst</span><br><span class="line">mkdir build64</span><br><span class="line">cd build64</span><br><span class="line">cmake -G "Visual Studio 15 2017 Win64" ../</span><br></pre></td></tr></table></figure><p>如果这一步成功会显示以下提示：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">-- The C compiler identification is MSVC 19.11.25547.0</span><br><span class="line">-- The CXX compiler identification is MSVC 19.11.25547.0</span><br><span class="line">-- Check for working C compiler: C:/Program Files (x86)/Microsoft Visual Studio/2017/Community/VC/Tools/MSVC/14.11.25503/bin/Hostx86/x64/cl.exe</span><br><span class="line">-- Check for working C compiler: C:/Program Files (x86)/Microsoft Visual Studio/2017/Community/VC/Tools/MSVC/14.11.25503/bin/Hostx86/x64/cl.exe -- works</span><br><span class="line">-- Detecting C compiler ABI info</span><br><span class="line">-- Detecting C compiler ABI info - done</span><br><span class="line">-- Check for working CXX compiler: C:/Program Files (x86)/Microsoft Visual Studio/2017/Community/VC/Tools/MSVC/14.11.25503/bin/Hostx86/x64/cl.exe</span><br><span class="line">-- Check for working CXX compiler: C:/Program Files (x86)/Microsoft Visual Studio/2017/Community/VC/Tools/MSVC/14.11.25503/bin/Hostx86/x64/cl.exe -- works</span><br><span class="line">-- Detecting CXX compiler ABI info</span><br><span class="line">-- Detecting CXX compiler ABI info - done</span><br><span class="line">-- Detecting CXX compile features</span><br><span class="line">-- Detecting CXX compile features - done</span><br><span class="line">-- The following ICU libraries were not found:</span><br><span class="line">--   data (required)</span><br><span class="line">--   i18n (required)</span><br><span class="line">--   io (required)</span><br><span class="line">--   test (required)</span><br><span class="line">--   tu (required)</span><br><span class="line">--   uc (required)</span><br><span class="line">-- Failed to find all ICU components (missing: ICU_INCLUDE_DIR ICU_LIBRARY _ICU_REQUIRED_LIBS_FOUND)</span><br><span class="line">-- Could NOT find ZLIB (missing: ZLIB_LIBRARY ZLIB_INCLUDE_DIR)</span><br><span class="line">-- Configuring done</span><br><span class="line">-- Generating done</span><br><span class="line">-- Build files have been written to: C:/Users/jtrmal/Documents/openfst/build64</span><br></pre></td></tr></table></figure><p>成功后会在build64目录下面生成一个openfst.sln文件，用vs2017打开这个文件，分别用Debug|x64和Release|x64来生成一遍，如下图，如果失败为0则代表编译通过。</p><img src="/posts/3944650563/2.jpg"><h2 id="配置OpenBLAS"><a href="#配置OpenBLAS" class="headerlink" title="配置OpenBLAS"></a>配置OpenBLAS</h2><p>首先也是从github上先将kaldi clone下来</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/kaldi-asr/kaldi.git kaldi</span><br></pre></td></tr></table></figure><p>然后我们就需要去配置线性代数库，这里有两个选择，一个是Intel MKL，一个是OpenBLAS。这里我选用OpenBLAS。用下面的命令来下载OpenBLAS的二进制包（在kaldi/tools目录下）：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">curl -L -O http://sourceforge.net/projects/openblas/files/v0.2.14/OpenBLAS-v0.2.14-Win64-int32.zip</span><br><span class="line">unzip OpenBLAS-v0.2.14-Win64-int32.zip</span><br></pre></td></tr></table></figure><p><strong>注意这里要下载Win64-int32版本，而不是Win64-int64版本</strong></p><h2 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h2><p>进入kaldi/windows路径想，将varialbe.props.dev复制一份重命名为variables.props，打开后将刚刚配置好的库修改为自己的路径：<br><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">    <span class="comment">&lt;!-- Change the following paths so they are correct on your machine --&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- Do not modify anything before this line --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">MKLDIR</span>&gt;</span>C:\Program Files\(x86)\IntelSWTools\compilers_and_libraries\windows\mkl\<span class="tag">&lt;/<span class="name">MKLDIR</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">OPENBLASDIR</span>&gt;</span>C:\Users\Yenda\Downloads\kaldi-svn\tools\OpenBLAS-v0.2.14-Win64-int32<span class="tag">&lt;/<span class="name">OPENBLASDIR</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">OPENFST</span>&gt;</span>C:\Users\jtrmal\Documents\openfst<span class="tag">&lt;/<span class="name">OPENFST</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">OPENFSTLIB</span>&gt;</span>C:\Users\jtrmal\Documents\openfst\build64<span class="tag">&lt;/<span class="name">OPENFSTLIB</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- Do not modify anything after this line --&gt;</span></span><br></pre></td></tr></table></figure></p><p>我们需要将OpenBLAS和Openfst修改为自己的路径，因为没有用到MKL就不用修改了。下面就是我修改后的路径：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">    <span class="comment">&lt;!-- Change the following paths so they are correct on your machine --&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- Do not modify anything before this line --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">MKLDIR</span>&gt;</span>C:\Program Files </span><br><span class="line">(x86)\IntelSWTools\compilers_and_libraries\windows\mkl\<span class="tag">&lt;/<span class="name">MKLDIR</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">OPENBLASDIR</span>&gt;</span>D:\git_home\kaldi\tools\OpenBLAS-v0.2.14-Win64-int32<span class="tag">&lt;/<span class="name">OPENBLASDIR</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">OPENFST</span>&gt;</span>D:\git_home\openfst<span class="tag">&lt;/<span class="name">OPENFST</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">OPENFSTLIB</span>&gt;</span>D:\git_home\openfst\build64<span class="tag">&lt;/<span class="name">OPENFSTLIB</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- Do not modify anything after this line --&gt;</span></span><br></pre></td></tr></table></figure><h2 id="产生工程文件"><a href="#产生工程文件" class="headerlink" title="产生工程文件"></a>产生工程文件</h2><p>同样还是在kaldi/windows路径下，因为我们是使用OpenBLAS所以就把kaldiwin_openblas.props复制一份重命名为kaldiwin.prosp。然后在windows路径下用git bash运行以下命令：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">./generate_solution.pl --vsver vs2017 --enable-openblas</span><br><span class="line">./get_version.pl</span><br></pre></td></tr></table></figure></p><h2 id="kaldi编译测试"><a href="#kaldi编译测试" class="headerlink" title="kaldi编译测试"></a>kaldi编译测试</h2><p>然后我们打开在kaldi/kaldiwin_vs2017_OPENBLAS这个新生成的文件夹，打卡里面的kaldiwin_vs2017.sln工程文件，这里面就包括了所有kaldi/src中*bin中的.cc文件。这时候需要来测试一下kaldi能否运行，首先要把<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># kaldi在Windows下的调试</span><br><span class="line">## 新建自己的kaldi项目</span><br><span class="line">在配置好kaldi之后，就可以开始调试和编写自己的使用kaldi的程序了。不过原来的kaldi项目中有630个项目或者称为解决方案，每次打开都要加载很久。所以我们可以新建一个空项目：</span><br><span class="line"></span><br><span class="line">&#123;% asset_img 4.jpg %&#125;</span><br><span class="line"></span><br><span class="line">### 添加引用</span><br><span class="line">然后点击左上角文件-&gt;添加-&gt;现有项目，切换到kaldi/kaldiwin_vs2017_OPENBLAS/kaldiwin路径下。</span><br><span class="line"></span><br><span class="line">&#123;% asset_img 5.jpg %&#125;</span><br><span class="line"></span><br><span class="line">最好把所有以kaldi开头的项目都添加进去（点进去具体的文件夹，添加.vcxproj文件），包含test的不用。不过如果你清楚你用的项目要用到哪些具体的引用，那么只添加特定的项目即可。那么要怎么看需要用到那些引用呢，这时就要回到之前那个包含630个项目的vs中去。</span><br><span class="line"></span><br><span class="line">&#123;% asset_img 6.jpg %&#125;</span><br><span class="line"></span><br><span class="line">比如说我想要提取mfcc特征，就可以去看看compute-mfcc-feats这个项目中以用了那些项目，然后在自己的项目提取mfcc特征项目中，也要以用相同的项目，那么就把对应的项目添加到自己的项目中，如下图：</span><br><span class="line"></span><br><span class="line">&#123;% asset_img 7.jpg %&#125;</span><br><span class="line"></span><br><span class="line">### 添加工程属性表</span><br><span class="line">配置好引用还需要我们去添加刚才配置好的vs工程属性表，点开左上菜单栏中的视图-&gt;属性管理器，*旧版的vs好像是在视图-&gt;其他窗口-&gt;属性管理器*。</span><br><span class="line"></span><br><span class="line">&#123;% asset_img 8.jpg %&#125;</span><br><span class="line"></span><br><span class="line">然后在自己的项目的Debug|64中添加variables.props kaldiwin.props openfst_debug.props（如果要release则添加对应的release版本）</span><br><span class="line"></span><br><span class="line">### 修改附加包含目录</span><br><span class="line">还差一步就大功告成，首先要在自己的项目中添加一个cpp文件，然后右键属性-&gt;C/C++-&gt;所有选项-&gt;附加包含目录，需要把kaldi/src目录添加进去</span><br><span class="line">![a7509168d8617a8e771cae04763c5941.png](evernotecid://88B7D2F7-E308-49B2-989E-D5AE88784154/appyinxiangcom/4510133/ENResource/p3587)</span><br><span class="line">配置好之后，就可以写自己的调用kaldi的程序了，之后也可以按照这样的方式来。</span><br><span class="line">* 在当前项目中文件-&gt;添加-&gt;新建项目</span><br><span class="line">* 添加需要用到的引用</span><br><span class="line">* 添加已经配置好的工程属性表</span><br><span class="line">* 最后把kaldi/src添加到附加包含目录就可以了</span><br><span class="line">* ***另外要记住调试模式要切换成Debug|x64***</span><br><span class="line"></span><br><span class="line">## 写自己的kaldi程序</span><br><span class="line">如果想写自己的调用kaldi的程序要怎么开始呢，最好的办法就是去看run.sh中用到了哪些命令，然后在看命令中C++代码是怎么做的。以提取mfcc特征为例，在声纹识别中，一般都是下面几条命令用来提取mfcc特征：</span><br><span class="line"></span><br><span class="line">```Shell</span><br><span class="line"># run.sh</span><br><span class="line"># Now make MFCC features.</span><br><span class="line"># mfccdir should be some place with a largish disk where you</span><br><span class="line"># want to store MFCC features.</span><br><span class="line">mfccdir=mfcc</span><br><span class="line">for x in train test; do</span><br><span class="line">steps/make_mfcc.sh --cmd &quot;$train_cmd&quot; --nj 10 data/$x exp/make_mfcc/$x $mfccdir</span><br><span class="line">sid/compute_vad_decision.sh --nj 10 --cmd &quot;$train_cmd&quot; data/$x exp/make_mfcc/$x $mfccdir</span><br><span class="line">utils/fix_data_dir.sh data/$x</span><br><span class="line">done</span><br></pre></td></tr></table></figure></p><p>具体的提取mfcc的特征程序就在steps/make_mfcc.sh中了</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> make_mfcc.sh</span><br><span class="line"><span class="meta">$</span>cmd JOB=1:$nj $logdir/make_mfcc_$&#123;name&#125;.JOB.log \</span><br><span class="line">extract-segments scp,p:$scp $logdir/segments.JOB ark:- \| \</span><br><span class="line">compute-mfcc-feats $vtln_opts --verbose=2 --config=$mfcc_config ark:- ark:- \| \</span><br><span class="line">copy-feats --compress=$compress $write_num_frames_opt ark:- \</span><br><span class="line">ark,scp:$mfccdir/raw_mfcc_$name.JOB.ark,$mfccdir/raw_mfcc_$name.JOB.scp \</span><br><span class="line">|| exit 1;</span><br></pre></td></tr></table></figure><p>里面具体提取mfcc特征的命令就应该是steps/make_mfcc.sh了，看下make_mfcc.sh，在经过一系列处理后，使用compute-mfcc-feat这个命令来提取mfcc特征的。我们就可以去看在featbin下的compute-mfcc-feat.cc中是如何提取mfcc特征的，下面就贴上我的提取mfcc并写入一个txt文件的代码：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;fstream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">"feat/feature-mfcc.h"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">"feat/wave-reader.h"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">"base/kaldi-math.h"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">"matrix/kaldi-matrix-inl.h"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">"matrix/kaldi-vector.h"</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc,<span class="keyword">char</span> * argv[])</span></span>&#123;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> kaldi;   <span class="comment">//要记住使用namespace kaldi</span></span><br><span class="line">        <span class="keyword">const</span> <span class="keyword">char</span> * Usage =</span><br><span class="line">        <span class="string">"my_kaldi.exe [wav_filename] [mfcc_filename] \n"</span>;</span><br><span class="line"><span class="function">ParseOptions <span class="title">po</span><span class="params">(Usage)</span></span>;</span><br><span class="line"></span><br><span class="line">po.Read(argc, argv);</span><br><span class="line"><span class="keyword">if</span> (po.NumArgs() != <span class="number">2</span>) &#123;</span><br><span class="line">po.PrintUsage();</span><br><span class="line">            <span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">string</span> wav_filename = po.GetArg(<span class="number">1</span>);</span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">string</span> mfcc_filename = po.GetArg(<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">/*读取wav文件*/</span></span><br><span class="line"><span class="built_in">std</span>::ifstream wav_file;</span><br><span class="line">wav_file.open(wav_filename, <span class="built_in">std</span>::ios_base::binary);</span><br><span class="line">WaveData wave;</span><br><span class="line">wave.Read(wav_file);</span><br><span class="line">SubVector&lt;BaseFloat&gt; waveform(wave.Data(), <span class="number">0</span>);<span class="comment">//将wav文件数据放到waveform中</span></span><br><span class="line">              </span><br><span class="line"><span class="comment">/*mfcc特征配置*/</span></span><br><span class="line">MfccOptions mfcc_opts;</span><br><span class="line">mfcc_opts.frame_opts.samp_freq = <span class="number">16000</span>;</span><br><span class="line">mfcc_opts.frame_opts.frame_length_ms = <span class="number">25</span>;</span><br><span class="line">mfcc_opts.frame_opts.frame_shift_ms = <span class="number">10</span>;</span><br><span class="line">mfcc_opts.frame_opts.preemph_coeff = <span class="number">0.95</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*提取mfcc特征*/</span></span><br><span class="line">Matrix&lt;BaseFloat&gt; mfcc_feature;</span><br><span class="line"><span class="function">Mfcc <span class="title">feat</span><span class="params">(mfcc_opts)</span></span>;</span><br><span class="line">feat.ComputeFeatures(waveform, wave.SampFreq(), <span class="number">1.0</span>, &amp;mfcc_feature);</span><br><span class="line">              </span><br><span class="line">    <span class="comment">/*写入到文件中*/</span></span><br><span class="line">        WriteKaldiObject(mfcc_feature,mfcc,<span class="literal">false</span>);</span><br><span class="line">        <span class="comment">//kaldi中都可以使用WriteKaldiObject来写使用到的kaldi对象</span></span><br><span class="line">&#125;</span><br><span class="line">       </span><br><span class="line"><span class="keyword">catch</span> (<span class="keyword">const</span> <span class="built_in">std</span>::exception &amp;e) &#123;</span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">cerr</span> &lt;&lt; e.what();</span><br><span class="line"><span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br><span class="line">       </span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="kaldi中的I-O接口简介"><a href="#kaldi中的I-O接口简介" class="headerlink" title="kaldi中的I/O接口简介"></a>kaldi中的I/O接口简介</h2><p>在windows上跑kaldi，不可避免地会用到kaldi中的I/O接口，比如读取在Linux下已经训练好的模型，或者读取在linux上提取的特征等。</p><h3 id="模型的读取"><a href="#模型的读取" class="headerlink" title="模型的读取"></a>模型的读取</h3><p>kaldi中的模型往往都是一个类，比如说声纹识别中用到的UBM类FullGmm，提取ivector的IvectorExtractor等等，对于这些类的提取都可以用ReadKaldiObject来完成</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> kaldi;</span><br><span class="line">FullGmm fgmm;                           <span class="comment">//首先要声明想要读取的模型的类</span></span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">string</span> ubmFile = <span class="string">"final.ubm"</span>;    <span class="comment">//然后确定文件名</span></span><br><span class="line">ReadKaldiObject(ubmFile, &amp;fgmm);</span><br></pre></td></tr></table></figure><p>对于其他的模型，也可以通过类似的方法来读取到内存中。如果想把模型等写出来也可以通过WriteKaldiObject来完成。</p><h3 id="table类型文件的读取"><a href="#table类型文件的读取" class="headerlink" title="table类型文件的读取"></a>table类型文件的读取</h3><ul><li style="list-style: none"><input type="checkbox"> 未完待续</li></ul><h1 id="kaldi在Windows下的移植"><a href="#kaldi在Windows下的移植" class="headerlink" title="kaldi在Windows下的移植"></a>kaldi在Windows下的移植</h1><p>此处的移植指的是能够使kaldi在一台没有开发环境下的电脑中正常运行。</p><h2 id="生成exe"><a href="#生成exe" class="headerlink" title="生成exe"></a>生成exe</h2><h2 id="生成dll"><a href="#生成dll" class="headerlink" title="生成dll"></a>生成dll</h2><h1 id="遇到的问题记录"><a href="#遇到的问题记录" class="headerlink" title="遇到的问题记录"></a>遇到的问题记录</h1><h2 id="cmake生成Openfst工程文件失败"><a href="#cmake生成Openfst工程文件失败" class="headerlink" title="cmake生成Openfst工程文件失败"></a>cmake生成Openfst工程文件失败</h2><img src="/posts/3944650563/9.jpg"><p>根据错误提示，应该是缺少了fst_test.h weight-tester.h algo_test.h，在openfst/src目录下搜索这几个文件，发现都在openfst\src\include\fst\test中，于是把几个文件都复制过来，然后再执行那条cmake的命令，就可以成功了~。</p><h2 id="缺少libopenblas-dll"><a href="#缺少libopenblas-dll" class="headerlink" title="缺少libopenblas.dll"></a>缺少libopenblas.dll</h2><p>当在命令行或git bash中运行生成好的exe时，会报错缺少libopenblas.dll：</p><img src="/posts/3944650563/3.png"><p>我们需要将之前下载的OpenBLAS中bin目录下的libopenblas.dll拷到和exe文件同一个文件夹中就可以执行了。</p><h2 id="mingw-dll下载"><a href="#mingw-dll下载" class="headerlink" title="mingw dll下载"></a>mingw dll下载</h2><p>包括libgcc_s_seh-1.dll libgfortran-3.dll libquadmath-0.dll，下载后同样需要放到和exe同一目录下。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">curl -L -O http://sourceforge.net/projects/openblas/files/v0.2.14/mingw64_dll.zip</span><br><span class="line">unzip mingw64_dll.zip</span><br></pre></td></tr></table></figure></p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p>官方Windows下安装指南：<br><a href="https://github.com/kaldi-asr/kaldi/blob/master/windows/INSTALL.md" target="_blank" rel="noopener">https://github.com/kaldi-asr/kaldi/blob/master/windows/INSTALL.md</a><br>一个中文的安装说明：<br><a href="https://www.jianshu.com/p/5494d6607789" target="_blank" rel="noopener">https://www.jianshu.com/p/5494d6607789</a><br>Windows下安装常见的问题：<br><a href="https://blog.csdn.net/qq_25867649/article/details/78356474?locationNum=8&amp;fps=1" target="_blank" rel="noopener">https://blog.csdn.net/qq_25867649/article/details/78356474?locationNum=8&amp;fps=1</a><br>kaldi中IO接口介绍：<br><a href="http://kaldi-asr.org/doc/io.html" target="_blank" rel="noopener">http://kaldi-asr.org/doc/io.html</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;其实不是特别推荐在Windows下使用kaldi，因为在egs下所有的脚本都无法运行，我也是弄了很久才在Windows下配置好kaldi，都一度差点弃坑。就连官方也说&lt;strong&gt;There is no commitment to support Windows. The Windows port of Kaldi is targeted at experienced developers who want to program their own apps using the kaldi libraries and are able to do the troubleshooting on their own.&lt;/strong&gt;就让我来把坑填平那么一点点吧🧐&lt;br&gt;
    
    </summary>
    
      <category term="声纹识别" scheme="http://yutouwd.github.io/categories/%E5%A3%B0%E7%BA%B9%E8%AF%86%E5%88%AB/"/>
    
    
      <category term="kaldi" scheme="http://yutouwd.github.io/tags/kaldi/"/>
    
      <category term="声纹识别" scheme="http://yutouwd.github.io/tags/%E5%A3%B0%E7%BA%B9%E8%AF%86%E5%88%AB/"/>
    
      <category term="Visual Studio" scheme="http://yutouwd.github.io/tags/Visual-Studio/"/>
    
  </entry>
  
  <entry>
    <title>博客折腾记录</title>
    <link href="http://yutouwd.github.io/posts/87e6cb09/"/>
    <id>http://yutouwd.github.io/posts/87e6cb09/</id>
    <published>2019-02-18T15:17:59.000Z</published>
    <updated>2019-02-26T12:41:44.697Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>之前一直没有记录修改&amp;优化博客的过程，其实这是一个不太好的习惯，现在都忘了自己修改过哪些地方了(虽然vscode可以标出来)，哪些修改对应了网站哪些变化。所以还是要记录一下修改的记录，为方便日后对博客持续优化。</p><h2 id="things-to-do"><a href="#things-to-do" class="headerlink" title="things to do"></a>things to do</h2><ul><li style="list-style: none"><input type="checkbox" checked> 修改站点下博客文章存放目录</li><li style="list-style: none"><input type="checkbox" checked> 侧边栏toc自动展开</li><li style="list-style: none"><input type="checkbox" checked> 评论系统更换为valine</li><li style="list-style: none"><input type="checkbox"> 站点自动备份系统</li><li style="list-style: none"><input type="checkbox"> 文章分类、归档页面优化</li><li style="list-style: none"><input type="checkbox"> 代码块优化</li><li style="list-style: none"><input type="checkbox" checked> next版本升级</li></ul><a id="more"></a><h2 id="修改站点下博客文章存放目录"><a href="#修改站点下博客文章存放目录" class="headerlink" title="修改站点下博客文章存放目录"></a>修改站点下博客文章存放目录</h2><p>这个其实是在找解决如何将侧边栏toc自动展开时，找到一篇<a href="https://blog.dongleizhang.com/posts/32005d86/" target="_blank" rel="noopener">博客</a>无意中发现的。原来那种年/月/日…的方式真的太挫了，于是就按照他的这种方式，生成一个永久链接。<br>首先安装hexo-abbrlink插件，使用命令 npm install hexo-abbrlink –save 即可。然后需要在站点配置文件，即hexo目录下的_config.yml文件中修改 permalink: :year/:month/:day/:title/ 为一下内容：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">permalink: posts/:abbrlink/</span><br><span class="line">abbrlink:</span><br><span class="line">  alg: crc32  <span class="comment">#support crc16(default) and crc32</span></span><br><span class="line">  rep: hex    <span class="comment">#support dec(default) and hex</span></span><br></pre></td></tr></table></figure><p>然后在hexo clean和hexo g &amp;&amp; hexo d即可。不过令人伤心的是，在重新生成文章链接后原来的阅读量也随之清零了😭，我这可怜的阅读量不知道什么时候才能四位数啊。</p><h2 id="侧边栏toc自动展开"><a href="#侧边栏toc自动展开" class="headerlink" title="侧边栏toc自动展开"></a>侧边栏toc自动展开</h2><p>目前在github上找到了几个issue:<a href="https://github.com/theme-next/hexo-theme-next/issues/307" target="_blank" rel="noopener">#307</a> <a href="https://github.com/iissnan/hexo-theme-next/issues/531" target="_blank" rel="noopener">#531</a> <a href="https://github.com/iissnan/hexo-theme-next/issues/710" target="_blank" rel="noopener">#710</a><br>具体的解决方法就是在themes/next/source/_custom/custom.styl中加入以下代码，可以自动展开二级标题。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">.post-toc .nav .nav-level-1&gt;.nav-child &#123; </span><br><span class="line">   display: block; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="评论系统更换为valine"><a href="#评论系统更换为valine" class="headerlink" title="评论系统更换为valine"></a>评论系统更换为valine</h2><p>真的受不了disqus，首先被河蟹了，然后即使能加载也非常的慢，界面也十分的丑。今天看到一些博客用了valine发现比disqus好看多了，抽时间赶紧把这个给改了。<br>一开始弄好了，但是发现刷新后评论就会消失。后来在github上问了下<a href="https://github.com/xCss/Valine/issues/159" target="_blank" rel="noopener">#159</a>，原来valine和next自带的统计阅读量会有冲突。然后还发现一个很严重的问题，一开始在选主题的时候没有仔细调研，就下了旧的next版本5.1.4。现在最新的next版本已经到6点多，并且在另外一个仓库中。所以又想把next换成最新的版本。</p><h2 id="站点自动备份系统"><a href="#站点自动备份系统" class="headerlink" title="站点自动备份系统"></a>站点自动备份系统</h2><p><a href="https://notes.doublemine.me/2015-07-06-%E8%87%AA%E5%8A%A8%E5%A4%87%E4%BB%BDHexo%E5%8D%9A%E5%AE%A2%E6%BA%90%E6%96%87%E4%BB%B6.html" target="_blank" rel="noopener">https://notes.doublemine.me/2015-07-06-%E8%87%AA%E5%8A%A8%E5%A4%87%E4%BB%BDHexo%E5%8D%9A%E5%AE%A2%E6%BA%90%E6%96%87%E4%BB%B6.html</a></p><h2 id="代码块优化"><a href="#代码块优化" class="headerlink" title="代码块优化"></a>代码块优化</h2><p>代码块mac风格<br><a href="https://blog.ihoey.com/posts/Hexo/2018-05-27-hexo-code-block.html" target="_blank" rel="noopener">https://blog.ihoey.com/posts/Hexo/2018-05-27-hexo-code-block.html</a><br>代码块复制(在next7.0中已经集成了代码块复制功能)<br><a href="https://qiming.info/Hexo%E5%8D%9A%E5%AE%A2%E4%B8%AD%E5%8A%A0%E5%85%A5%E4%BB%A3%E7%A0%81%E5%9D%97%E5%A4%8D%E5%88%B6%E5%8A%9F%E8%83%BD/" target="_blank" rel="noopener">https://qiming.info/Hexo%E5%8D%9A%E5%AE%A2%E4%B8%AD%E5%8A%A0%E5%85%A5%E4%BB%A3%E7%A0%81%E5%9D%97%E5%A4%8D%E5%88%B6%E5%8A%9F%E8%83%BD/</a></p><h2 id="next版本升级"><a href="#next版本升级" class="headerlink" title="next版本升级"></a>next版本升级</h2><p>升级到7.0，先将就的themes/next文件夹重命名为next-old，然后在把最新的next下载到themes/next中，在把之前的一些配置修改一下。不知道为什么新的字数统计加载不出来，还是想用回原来的。现在next-old/_config.yml中找到原来的wordcount设置字段复制到新的next的_cogfig.yml中。先找到了整个网站页低的字数统计是在theme/next/layout/footer.swig中设置的。将旧的wordcount的设置复制过去，就可以了。<br><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&#123;% if theme.post_wordcount.totalcount %&#125;</span><br><span class="line">  <span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"post-meta-divider"</span>&gt;</span>|<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"post-meta-item-icon"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">i</span> <span class="attr">class</span>=<span class="string">"fa fa-area-chart"</span>&gt;</span><span class="tag">&lt;/<span class="name">i</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">  &#123;% if theme.post_wordcount.item_text %&#125;</span><br><span class="line">    <span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"post-meta-item-text"</span>&gt;</span>&#123;&#123; __('文字总数') &#125;&#125;&amp;#58;<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">  &#123;% endif %&#125;</span><br><span class="line">  <span class="tag">&lt;<span class="name">span</span> <span class="attr">title</span>=<span class="string">"&#123;&#123; __('post.totalcount') &#125;&#125;"</span>&gt;</span>&#123;#</span><br><span class="line">  #&#125;&#123;&#123; totalcount(site, '0,0.0a') &#125;&#125;&#123;#</span><br><span class="line">#&#125;<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">&#123;% endif %&#125;</span><br></pre></td></tr></table></figure></p><p>然后还需要修改每篇文章上的显示设置，在旧的next主题github地址<a href="https://github.com/iissnan/hexo-theme-next" target="_blank" rel="noopener">https://github.com/iissnan/hexo-theme-next</a> 中搜索 post_wordcount 可以找到在next/layout/_marco/post.swig中有用到，那么这里就应该是设置每篇文章的字数统计的地方。再把旧的和新的对比一下把旧的包括post_wordcount的代码复制过去，就大功告成。</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">&#123;% if theme.post_wordcount.wordcount or theme.post_wordcount.min2read %&#125;</span><br><span class="line">  <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"post-wordcount"</span>&gt;</span></span><br><span class="line">    &#123;% if theme.post_wordcount.wordcount %&#125;</span><br><span class="line">      &#123;% if not theme.post_wordcount.separated_meta %&#125;</span><br><span class="line">        <span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"post-meta-divider"</span>&gt;</span>|<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">      &#123;% endif %&#125;</span><br><span class="line">      <span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"post-meta-item-icon"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">i</span> <span class="attr">class</span>=<span class="string">"fa fa-file-word-o"</span>&gt;</span><span class="tag">&lt;/<span class="name">i</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">      &#123;% if theme.post_wordcount.item_text %&#125;</span><br><span class="line">        <span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"post-meta-item-text"</span>&gt;</span>&#123;&#123; __('字数统计') &#125;&#125;&amp;#58;<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">      &#123;% endif %&#125;</span><br><span class="line">      <span class="tag">&lt;<span class="name">span</span> <span class="attr">title</span>=<span class="string">"&#123;&#123; __('post.wordcount') &#125;&#125;"</span>&gt;</span></span><br><span class="line">        &#123;&#123; wordcount(post.content) &#125;&#125;</span><br><span class="line">      <span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">    &#123;% endif %&#125;</span><br><span class="line"></span><br><span class="line">    &#123;% if theme.post_wordcount.wordcount and theme.post_wordcount.min2read %&#125;</span><br><span class="line">      <span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"post-meta-divider"</span>&gt;</span>|<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">    &#123;% endif %&#125;</span><br><span class="line"></span><br><span class="line">    &#123;% if theme.post_wordcount.min2read %&#125;</span><br><span class="line">      <span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"post-meta-item-icon"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">i</span> <span class="attr">class</span>=<span class="string">"fa fa-clock-o"</span>&gt;</span><span class="tag">&lt;/<span class="name">i</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">      &#123;% if theme.post_wordcount.item_text %&#125;</span><br><span class="line">        <span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"post-meta-item-text"</span>&gt;</span>&#123;&#123; __('阅读时间') &#125;&#125; &amp;asymp;<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">      &#123;% endif %&#125;</span><br><span class="line">      <span class="tag">&lt;<span class="name">span</span> <span class="attr">title</span>=<span class="string">"&#123;&#123; __('post.min2read') &#125;&#125;"</span>&gt;</span></span><br><span class="line">        &#123;&#123; min2read(post.content) &#125;&#125;</span><br><span class="line">      <span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">    &#123;% endif %&#125;</span><br><span class="line">  <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">&#123;% endif %&#125;</span><br></pre></td></tr></table></figure><h2 id="教程收藏"><a href="#教程收藏" class="headerlink" title="教程收藏"></a>教程收藏</h2><p><a href="http://yearito.cn/tags/Hexo/" target="_blank" rel="noopener">http://yearito.cn/tags/Hexo/</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;之前一直没有记录修改&amp;amp;优化博客的过程，其实这是一个不太好的习惯，现在都忘了自己修改过哪些地方了(虽然vscode可以标出来)，哪些修改对应了网站哪些变化。所以还是要记录一下修改的记录，为方便日后对博客持续优化。&lt;/p&gt;
&lt;h2 id=&quot;things-to-do&quot;&gt;&lt;a href=&quot;#things-to-do&quot; class=&quot;headerlink&quot; title=&quot;things to do&quot;&gt;&lt;/a&gt;things to do&lt;/h2&gt;&lt;ul&gt;
&lt;li style=&quot;list-style: none&quot;&gt;&lt;input type=&quot;checkbox&quot; checked&gt; 修改站点下博客文章存放目录&lt;/li&gt;
&lt;li style=&quot;list-style: none&quot;&gt;&lt;input type=&quot;checkbox&quot; checked&gt; 侧边栏toc自动展开&lt;/li&gt;
&lt;li style=&quot;list-style: none&quot;&gt;&lt;input type=&quot;checkbox&quot; checked&gt; 评论系统更换为valine&lt;/li&gt;
&lt;li style=&quot;list-style: none&quot;&gt;&lt;input type=&quot;checkbox&quot;&gt; 站点自动备份系统&lt;/li&gt;
&lt;li style=&quot;list-style: none&quot;&gt;&lt;input type=&quot;checkbox&quot;&gt; 文章分类、归档页面优化&lt;/li&gt;
&lt;li style=&quot;list-style: none&quot;&gt;&lt;input type=&quot;checkbox&quot;&gt; 代码块优化&lt;/li&gt;
&lt;li style=&quot;list-style: none&quot;&gt;&lt;input type=&quot;checkbox&quot; checked&gt; next版本升级&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="个人博客" scheme="http://yutouwd.github.io/categories/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"/>
    
    
      <category term="个人博客" scheme="http://yutouwd.github.io/tags/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"/>
    
      <category term="Hexo" scheme="http://yutouwd.github.io/tags/Hexo/"/>
    
      <category term="Next" scheme="http://yutouwd.github.io/tags/Next/"/>
    
  </entry>
  
  <entry>
    <title>深度学习在声纹识别中的应用</title>
    <link href="http://yutouwd.github.io/posts/600d0d5d/"/>
    <id>http://yutouwd.github.io/posts/600d0d5d/</id>
    <published>2019-02-02T00:39:57.000Z</published>
    <updated>2019-02-21T16:13:20.949Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>随着深度学习的迅猛发展，神经网络在越来越多的方向得到了广泛的应用，声纹识别也不例外。有越来越多的使用神经网络的方法来进行声纹识别的文章，并且都取得了不错的效果。最近也看了挺多文章的，总的来说，大致可以分为两个方向：feature learning,大概就是训练一个神经网络当作特征提取器，然后使用提取出来代表说话人的特征再做分类；End to end就是指直接输入两段语音，然后通过神经网络来判断这两段语音是否来自同一个人。<br><a id="more"></a></p><h1 id="Feature-Learning"><a href="#Feature-Learning" class="headerlink" title="Feature Learning"></a>Feature Learning</h1><h2 id="d-vector"><a href="#d-vector" class="headerlink" title="d-vector"></a>d-vector</h2><p>最早在2014年Google将神经网络用于声纹识别：<a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.674.3686&amp;rep=rep1&amp;type=pdf" target="_blank" rel="noopener">Deep Neural Networks for Small Footprint Text-Dependent</a>。它使用了一个四层的全连接层的网络来完成文本相关的声纹识别任务。它的结构如下：</p><p><img src="/upload_image/3.png" alt=""></p><p>它使用40维的filterbank特征（和MFCC相比少了离散余弦变换），然后使用当前帧的以及它的前后两帧作为输入，即一个120维的一维向量作为输入。经过四层的全连接层，每层有256个节点，使用maxout作为激活函数，最后两层加入dropout。训练时使用帧级别（frame level）的特征，使用softmax分类。</p><p>在网络训练好之后，将之前的最后一层移除，使用隐藏层的最后一层作为输出，即使用这一层当作一段语音所提取出的特征。在注册和验证过程中，使用一段语音（utterance）进行分帧，提取filterbank特征，输入到神经网络，然后将全部帧所对应的隐藏层的最后一层求均值作为这一段语音的特征。在打分的过程中使用consine距离来判断两段语音是否来自同一个人。不过它取得的效果并不是很好，等错误率没有i-vector高。但是在加入噪声的情况下稳定性要稍微好一些。</p><p>这种结构的系统可以理解为使用神经网络来做一个特征提取的任务。在训练的过程中，使用softmax来对训练集中的不同说话人做一个分类。而到了注册和验证的阶段，就将这个softmax层去掉，使用倒数第二层（或者说隐藏层的最后一层）当作神经网络的输出，使用这一层当作说话人的特征，论文中也称为d-vector。然后再使用consine similarity来进行打分判别。</p><h2 id="d-vector改进"><a href="#d-vector改进" class="headerlink" title="d-vector改进"></a>d-vector改进</h2><p>前一篇文章虽然网络的结构比较简单，但是是第一篇完全使用神经网络用于声纹识别的文章。之后也有不少人在此基础上做了改进，下面一篇就是对d-vector对改进：<a href="https://arxiv.org/pdf/1705.03670.pdf" target="_blank" rel="noopener">Deep Speaker Feature Learning for Text-independent Speaker Verification</a>这篇文章改进了之前的结构，并且用于文本不相关的任务当中。他的结构如下：</p><p><img src="/upload_image/4.png" alt=""></p><p>它还是使用了40维filterbank作为输入特征，不过这里使用一帧以及它前后相邻的4帧，即一共九帧作为整个神经网络的输入（9*40）。然后经过两个卷积–池化层，然后再经过一个bottleneck层，之后再有两层time-delay层，以及一个全连接层，最后是一个5000维的softmax输出。</p><p>到了注册和测试阶段，同样是将最后的分类层去除，使用隐藏层的最后一层作为提取出来的特征，称为d-vector。并且将帧级别（frame level）的d-vector求均值得到utterance level的d-vector作为一段语音所代表的特征。最后文章也比较了几种分类器的效果，分别是consine、LDA和PLDA。在i-vector系统中PLDA有着最低的EER，而在d-vector中LDA则表现更加优异。（不太清楚这里是用LDA做降维后再接consine similarity还是用LDA做分类）（但是我现在还不太明白LDA是怎么进行分类的，不过找到一篇文章，分别介绍了使用LDA用于分类和降维的方法：<a href="https://towardsdatascience.com/is-lda-a-dimensionality-reduction-technique-or-a-classifier-algorithm-eeed4de9953a" target="_blank" rel="noopener">Is LDA a dimensionality reduction technique or a classifier algorithm?</a>）</p><h2 id="x-vector"><a href="#x-vector" class="headerlink" title="x-vector"></a>x-vector</h2><p>在18年David Snyder也就是kaldi的作者之一提出了<a href="http://www.danielpovey.com/files/2018_icassp_xvectors.pdf" target="_blank" rel="noopener">x-vector: Robust DNN Embedding for Speaker Recognition</a>，也是对于前面网络的改进，在训练的数据量较大时，可以有较低的EER。它的网络结构如下表：</p><p><img src="/upload_image/5.png" alt=""></p><p>看了下kaldi中的代码，感觉这里和之前的time delay有点不同。首先输入是24维的filterbank特征，使用一帧以及前后2两帧，一共5帧一个120维的一维向量作为输入，输出长度为512。如果当前时刻为t，则第二层的输入为t-2、t和t+2时刻的第一层的输入。第三层同理，使用了第二层的t-3、t和t+3时刻作为输入。第四第五就是普通的全连接层。然后到了一个stats pooling，kaldi中的注释说到：Layer after this are segment level，并且segment size是[0,max_chunk_size]，在脚本中这个max_chunk_size的大小为10000，这里就是表格中的T。这一层做的是什么呢，就是求一下之前输出的统计值，我看在脚本中是mean+stddev，也就是均值加上标准差。之后后面就是两个全连接层。最后接上一个softmax分类。</p><p>在网络训练好之后，把segment7和softmax层都去掉，使用segment6作为提取出来的特征，成为x-vector，然后再使用LDA降维和PLDA打分。在kaldi中，x-vector的脚本还做了其他很多操作，包括使用噪声对数据进行增强，去除时间过短的utt，然后还需要去除utt较少的speaker等。</p><h1 id="End-to-End"><a href="#End-to-End" class="headerlink" title="End to End"></a>End to End</h1><p>接下来就是end to end的结构，和之前的feature learning的结构相比，end to end不需要再把训练好的网络再去掉最后的那么一两层，直接输入两段语音就可以判断这语音是否来自同一个人了。end to end的最大的特点就是在训练的时候需要挑选三段语音：首先需要确定一个anchor，即目标语音；然后还需要选来自同一个说话人的正样本，和来自不同说话人的负样本。训练时候的目标就是希望来自同一个人的语音（positive pair）的embedding要极可能的相似，而来自不同人的语音（negative pair）则要尽可能的不同。在训练完成之后，就可以直接输入两段语音然后判断他们是否来自同一个人了。</p><h2 id="Network-in-Network"><a href="#Network-in-Network" class="headerlink" title="Network in Network"></a>Network in Network</h2><p>同样是David Snyder再16年发表的一篇文章：<a href="http://www.danielpovey.com/files/2016_slt_xvector.pdf" target="_blank" rel="noopener">Deep Neural Network-Based Speaker Embeddings for End-to-End Speaker Verification</a>，它使用了time delay Network in Network的网络结构，系统的结构如下：</p><p><img src="/upload_image/6.png" alt=""></p><p>首先网络的输入是MFCC特征，每一帧提取20维的MFCC特征，然后取前后各4帧一共9帧共180维的向量作为输入。然后再输入到深度神经网络当中去，它的网络的具体结构如下：<em>(这是另外一篇文章中比较feature learning和E2E两种的模型的所画的图，那篇论文图更加直观一些：<a href="https://arxiv.org/pdf/1706.07859.pdf" target="_blank" rel="noopener">Deep Speaker Verification: Do We Need End-to-End</a>）</em> </p><p><img src="/upload_image/7.png" alt=""></p><p>这篇文章使用40维的filterbank特征，选用当前帧以及前后各一帧，一共3帧共120维的向量作为输入。然后是time delay层，取[t-2,t+1]时刻共四个时刻600维向量作为输入经过一个1000维全连接层和500维全连接层，输出到下一个NIN中。一共有3个time delayNIN，这里最后一个time delay NIN再接一个150维的全连接层，然后再求统计值（均值和标准差）这里的方式应该和x-vector是类似的，都是求一段语音前面的再进行一个statistics pooling，最后再有一个NIN，这里就没有time delay了，再加上一个150维的全连接层。</p><p>他这里的loss设计的也挺复杂的，我也还是不是特别地理解，它的公式如下：<br><img src="/upload_image/8.png" alt=""></p><h2 id="Triplet-Loss"><a href="#Triplet-Loss" class="headerlink" title="Triplet Loss"></a>Triplet Loss</h2><p>自从triplet loss在人脸识别中取得成功之后，也很多人在声纹识别中也用了triplet loss。这里就选一篇来介绍下：<a href="https://www.isca-speech.org/archive/Interspeech_2017/pdfs/1608.PDF" target="_blank" rel="noopener">End-to-End Text-Independent Speaker Verification with Triplet Loss on Short Utterance</a>。首先triplet loss的公式如下：</p><p>$$L=\sum_{i}[||f(x_i^a)-f(x_i^p)||_2^2-||f(x_i^a)-f(x_i^n)||_2^2+\alpha]$$</p><p>其中上标a代表anchor，上标p代表postive，上标n代表negative，$\alpha$是一个经验值。Triplet loss的思想很简单，就是希望positive pair的欧式距离要尽可能的小，而negative pair的欧式距离则要尽可能的大。</p><p>对于使用triplet loss的网络来说，triplet的选取非常重要。首先，我们不可能选取全部可能的triplet，因为这样做需要的计算量非常的大。因此选取出更加有效的triplet进行训练既会提高训练的效果也会提高训练的速度。这篇文章中的triplet选取的方式如下：首先一次选出60个说话人，然后每个人随机选择40段语音，这样一个epoch一共就有60*40*39/2=46800个triplet。然后通过选取满足当下面公式alpha=0.2时的triplet拿去训练。</p><p>这篇文章的选用的网络结构是Inception-resnet-v1，关于这个网络的介绍网上已经有非常多了，我这里也就不做详细的介绍了。这篇文章使用了语谱图作为神经网络的输入，相当于就是一个图像识别的问题了。</p><h2 id="Deep-Speaker"><a href="#Deep-Speaker" class="headerlink" title="Deep Speaker"></a>Deep Speaker</h2><p>基于triplet loss的文章还有很多，更多的就是选用不同的网络结构，如百度的<a href="https://arxiv.org/pdf/1705.02304.pdf" target="_blank" rel="noopener">Deep Speaker: an End-to-End Neural Speaker Embedding System</a>,他就对比了使用ResNet和GRU的效果。之后的改进方向也可是选用更加更深层的神经网络，或者是更合理的结构。可以看到随着深度学习技术的发展，声纹识别中也在不断的应用最新的技术</p><h1 id="两者的区别"><a href="#两者的区别" class="headerlink" title="两者的区别"></a>两者的区别</h1><p>两者的区别大致如下：feature learning的思路就是使用神经网络来提取特征，它在训练的时候和验证的时候网络的结构会有所不同。在训练的时候，最后一般都使用softmax为训练集做分类。而到了验证的时候，就需要把softmax层去掉，使用倒数第二层或第三层作为提取出来的特征，然后在使用consine距离或者plda模型来进行打分判别。而end to end的思路就是去训练神经网络，使其能直接判断两段语音的相似度。<a href="https://arxiv.org/pdf/1706.07859.pdf" target="_blank" rel="noopener">Deep Speaker Verification: Do We Need End-to-End</a>这篇文章也列举来这两种结构的不同之处：</p><ul><li>不同的模型结构：end to end包括了speaker embedding(front-end)和scoring(back-end)，这两个被联合起来去训练成一个完整网络；feature learing就只包括embedding这一步。</li><li>不同的训练目标：end to end的训练目标是判别一对语音使来自同一个人还是不同的人；feature learning是判别在训练集中的说话人。</li><li>不同的训练方法：end to end是使用一对对的语音进行训练，语音对选取的好坏就会很大程度影响训练的效果；feature learning是一种one-hot式的训练方式，相比于end to end来说更容易去训练。</li><li>不同的泛化能力：end to end训练好之后只能用在声纹识别的任务当中去；feature learning还可以在其他的语音任务中去使用。</li></ul><h1 id="为什么i-vector依然坚挺"><a href="#为什么i-vector依然坚挺" class="headerlink" title="为什么i-vector依然坚挺"></a>为什么i-vector依然坚挺</h1><p>之前在知乎上看到这样的一个问题：<a href="https://www.zhihu.com/question/67471632" target="_blank" rel="noopener">为什么在说话人识别技术中，i-vector+plda面对神经网络依然坚挺</a>在目前最前沿的说话人识别系统中，仍然有不少是基于i-vector+PLDA的，在2017年ICASSP和Interspeech中，基于i-vector的说话人识别论文数量和基于神经网络的论文数依然可以抗衡。在神经网络席卷了机器学习众多领域的今天，为什么i-vector依然能够坚挺地存在呢？它有什么优点是神经网络所没有的？最高票的答主做了很好的回答，这里概括一下：</p><blockquote><p>为什么在语音识别中DNN的应用会带来如此明显的提升，在说话人识别任务中却给人一种挣扎的感觉？这和任务属性是直接相关的，语音识别中，输出的是senone，不存在集外的概念。任何一句话里面的音素都能找到它对应的节点。但是说话人识别不一样，我们不可能要求测试的人在训练过程中出现，更不可能直接训练一个所有人的分类器。因此我们需要找到一个隐变量空间，每个人都是空间上的一个点，可以用这个空间的一组基来表示。i-vector就是找到了这样的一个隐变量空间。</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;随着深度学习的迅猛发展，神经网络在越来越多的方向得到了广泛的应用，声纹识别也不例外。有越来越多的使用神经网络的方法来进行声纹识别的文章，并且都取得了不错的效果。最近也看了挺多文章的，总的来说，大致可以分为两个方向：feature learning,大概就是训练一个神经网络当作特征提取器，然后使用提取出来代表说话人的特征再做分类；End to end就是指直接输入两段语音，然后通过神经网络来判断这两段语音是否来自同一个人。&lt;br&gt;
    
    </summary>
    
      <category term="声纹识别" scheme="http://yutouwd.github.io/categories/%E5%A3%B0%E7%BA%B9%E8%AF%86%E5%88%AB/"/>
    
    
      <category term="声纹识别" scheme="http://yutouwd.github.io/tags/%E5%A3%B0%E7%BA%B9%E8%AF%86%E5%88%AB/"/>
    
      <category term="深度学习" scheme="http://yutouwd.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Kaldi中的声纹识别</title>
    <link href="http://yutouwd.github.io/posts/364e185b/"/>
    <id>http://yutouwd.github.io/posts/364e185b/</id>
    <published>2019-01-31T01:18:34.000Z</published>
    <updated>2019-02-21T10:48:44.139Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>前段时间一直到在使用kaldi来做声纹识别，算是可以把整个ivector的例程可以跑下来，也可以根据例程来改写脚本，使用自己的数据来训练和测试。接下来可能要去做其他的项目了，所以要趁着还记得的时候赶紧写个总结，也算是对之前的工作也算是归纳一下。<br><a id="more"></a></p><h2 id="kaldi的安装"><a href="#kaldi的安装" class="headerlink" title="kaldi的安装"></a>kaldi的安装</h2><p>kaldi在Linux下的安装总的来说还是比较简单的，首先是先进入tools中运行extras/check_dependenices.sh看下还有哪些依赖项没有安装，然后就可以按照他的提示来安装依赖项目。安装完依赖项之后就分别进入tools目录和src目录下执行命令make -j8，其中8时cpu可以同时运行的线程数量。这个过程还是需要一定时间的。在make完之后就可以运行一个小的例程来看下有没有成功地安装kaldi，我们进入到egs/yesno/s5目录下然后运行run.sh脚本，这是一个判断语音中说的是yes还是no的程序，他会自动下载数据并训练和测试，最终可以有0.0%的WER，这就代表kaldi安装成功啦✌️</p><h2 id="运行aishell例程"><a href="#运行aishell例程" class="headerlink" title="运行aishell例程"></a>运行aishell例程</h2><p>首先我们来看下kaldi下的目录：</p><p><img src="/upload_image/1.png" alt=""></p><ul><li>egs：保存了各种例程，均使用脚本编写，以使用的数据库的名字命名。在下一级目录中以s开头的文件是语音识别，以v开头的是声纹识别，一般v1就是使用i-vector的方法来进行声纹识别。</li><li>src：保存了kaldi的C++代码。</li><li>tools：包括了kaldi依赖的库和一些实用的脚本。</li><li>windows：包括了在Windows下安装需要的一些工具和配置文件</li></ul><p>接下来我们就来跑一下aishell的声纹识别例程，在egs/aishell/v1中的run.sh就包括了整个声纹识别的流程，最好将run.sh中的命令复制到另外一个脚本中，一句一句地执行，这样就能及时发现错误然后修改。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">data=/<span class="built_in">export</span>/a05/xna/data</span><br><span class="line">data_url=www.openslr.org/resources/33</span><br><span class="line"></span><br><span class="line">. ./cmd.sh</span><br><span class="line">. ./path.sh</span><br><span class="line"></span><br><span class="line"><span class="built_in">set</span> -e <span class="comment"># exit on error</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">local</span>/download_and_untar.sh <span class="variable">$data</span> <span class="variable">$data_url</span> data_aishell</span><br><span class="line"><span class="built_in">local</span>/download_and_untar.sh <span class="variable">$data</span> <span class="variable">$data_url</span> resource_aishell</span><br><span class="line"></span><br><span class="line"><span class="comment"># Data Preparation</span></span><br><span class="line"><span class="built_in">local</span>/aishell_data_prep.sh <span class="variable">$data</span>/data_aishell/wav <span class="variable">$data</span>/data_aishell/transcript</span><br></pre></td></tr></table></figure><p>首先是数据准备阶段，如果没有下载数据，脚本也可以自动下载和解压；如果下载好了就要把data的路径改成自己存放数据的路径。之后的cmd.sh和path.sh分别是设置执行命令的方式和kaldi的路径。如果我们是在自己的电脑上运行，就需要进入到cmd.sh中，把queue.pl修改成run.pl。path.sh就是设置和kaldi相关的路径，如果是例程的话就不用修改了。配置好之后就开始下载和解压数据。</p><p>之后就是最关键的部分了，准备一些下面环节需要的文档，使用aishell_data_prep.sh这个脚本来生成。声纹识别需要用到的分别是utt2spk spk2utt wav.scp这三个文件。其中utt指的是utterance代表一个音频文件的文件名，spk代表speaker是说话人的ID，这里在下一节做详细的介绍。如果是做语音识别，还需要text文件，这里就不做介绍了。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Now make MFCC  features.</span></span><br><span class="line"><span class="comment"># mfccdir should be some place with a largish disk where you</span></span><br><span class="line"><span class="comment"># want to store MFCC features.</span></span><br><span class="line">mfccdir=mfcc</span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> train <span class="built_in">test</span>; <span class="keyword">do</span></span><br><span class="line">  steps/make_mfcc.sh --cmd <span class="string">"<span class="variable">$train_cmd</span>"</span> --nj 10 data/<span class="variable">$x</span> exp/make_mfcc/<span class="variable">$x</span> <span class="variable">$mfccdir</span></span><br><span class="line">  sid/compute_vad_decision.sh --nj 10 --cmd <span class="string">"<span class="variable">$train_cmd</span>"</span> data/<span class="variable">$x</span> exp/make_mfcc/<span class="variable">$x</span> <span class="variable">$mfccdir</span></span><br><span class="line">  utils/fix_data_dir.sh data/<span class="variable">$x</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><p>在准备好数据之后就要开始提取mfcc特征了（make_mfcc的过程中也包括了分帧加窗），进行端点检测（VAD），以及检查文件符不符合要求对文件进行排序（其实我也没有看太懂fix_data_dir.sh这个脚本到底做了什么😑)</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># train diag ubm</span></span><br><span class="line">sid/train_diag_ubm.sh --nj 10 --cmd <span class="string">"<span class="variable">$train_cmd</span>"</span> --num-threads 16 \</span><br><span class="line">  data/train 1024 exp/diag_ubm_1024</span><br><span class="line"></span><br><span class="line"><span class="comment">#train full ubm</span></span><br><span class="line">sid/train_full_ubm.sh --nj 10 --cmd <span class="string">"<span class="variable">$train_cmd</span>"</span> data/train \</span><br><span class="line">  exp/diag_ubm_1024 exp/full_ubm_1024</span><br><span class="line"></span><br><span class="line"><span class="comment">#train ivector</span></span><br><span class="line">sid/train_ivector_extractor.sh --cmd <span class="string">"<span class="variable">$train_cmd</span> --mem 10G"</span> \</span><br><span class="line">  --num-iters 5 exp/full_ubm_1024/final.ubm data/train \</span><br><span class="line">  exp/extractor_1024</span><br></pre></td></tr></table></figure><p>再接下来就是训练UBM和ivector extractor了，这里需要注意的是训练ivector extractor的脚本会默认同时执行程序非常多，会占用很高的内存导致内存溢出。我们需要进入train_ivector_extractor.sh中修改一下。它默认同时执行的程序数量为nj*num_thread*num_processes,在16G内存下我把这三个参数都改为2才能跑通。这里也还有两个超参数可以修改，分别是UBM的维数和ivector的维数，UBM的维数就直接在run.sh中修改就行，train_diag_ubm.sh中data/train后面那个参数就是UBM的维数，默认为1024。要修改ivector的维数就同样需要进到train_ivector_extractor.sh中修改ivector_dim，默认为400。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#extract ivector</span></span><br><span class="line">sid/extract_ivectors.sh --cmd <span class="string">"<span class="variable">$train_cmd</span>"</span> --nj 10 \</span><br><span class="line">  exp/extractor_1024 data/train exp/ivector_train_1024</span><br><span class="line"></span><br><span class="line"><span class="comment">#train plda</span></span><br><span class="line"><span class="variable">$train_cmd</span> exp/ivector_train_1024/<span class="built_in">log</span>/plda.log \</span><br><span class="line">  ivector-compute-plda ark:data/train/spk2utt \</span><br><span class="line">  <span class="string">'ark:ivector-normalize-length scp:exp/ivector_train_1024/ivector.scp  ark:- |'</span> \</span><br><span class="line">  exp/ivector_train_1024/plda</span><br></pre></td></tr></table></figure><p>训练完ivector之后就要开始提取训练集的ivector了，然后用训练集的ivector来训练plda模型用于打分。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># split the test to enroll and eval</span></span><br><span class="line">mkdir -p data/<span class="built_in">test</span>/enroll data/<span class="built_in">test</span>/<span class="built_in">eval</span></span><br><span class="line">cp data/<span class="built_in">test</span>/&#123;spk2utt,feats.scp,vad.scp&#125; data/<span class="built_in">test</span>/enroll</span><br><span class="line">cp data/<span class="built_in">test</span>/&#123;spk2utt,feats.scp,vad.scp&#125; data/<span class="built_in">test</span>/<span class="built_in">eval</span></span><br><span class="line"><span class="built_in">local</span>/split_data_enroll_eval.py data/<span class="built_in">test</span>/utt2spk  data/<span class="built_in">test</span>/enroll/utt2spk  data/<span class="built_in">test</span>/<span class="built_in">eval</span>/utt2spk</span><br><span class="line">trials=data/<span class="built_in">test</span>/aishell_speaker_ver.lst</span><br><span class="line"><span class="built_in">local</span>/produce_trials.py data/<span class="built_in">test</span>/<span class="built_in">eval</span>/utt2spk <span class="variable">$trials</span></span><br><span class="line">utils/fix_data_dir.sh data/<span class="built_in">test</span>/enroll</span><br><span class="line">utils/fix_data_dir.sh data/<span class="built_in">test</span>/<span class="built_in">eval</span></span><br></pre></td></tr></table></figure><p>之后就要将测试集分为注册集和验证集，这一步主要通过loacl/split_data_enroll_eval.py这个脚本来完成，我们先来看一下这个脚本：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># split_data_enroll_eval.py</span></span><br><span class="line"><span class="keyword">import</span> sys,random</span><br><span class="line"></span><br><span class="line">dictutt = &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> open(sys.argv[<span class="number">1</span>]):</span><br><span class="line">  line = line.rstrip(<span class="string">'\r\t\n '</span>)</span><br><span class="line">  utt, spk = line.split(<span class="string">' '</span>)</span><br><span class="line">  <span class="keyword">if</span> spk <span class="keyword">not</span> <span class="keyword">in</span> dictutt:</span><br><span class="line">    dictutt[spk] = []</span><br><span class="line">  dictutt[spk].append(utt)</span><br><span class="line"></span><br><span class="line">fenroll = open(sys.argv[<span class="number">2</span>], <span class="string">'w'</span>)</span><br><span class="line">feval = open(sys.argv[<span class="number">3</span>], <span class="string">'w'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> key <span class="keyword">in</span> dictutt:</span><br><span class="line">  utts = dictutt[key]</span><br><span class="line">  random.shuffle(utts)</span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, len(utts)):</span><br><span class="line">    line = utts[i] + <span class="string">' '</span> + key</span><br><span class="line">    <span class="keyword">if</span>(i &lt; <span class="number">3</span>):</span><br><span class="line">      fenroll.write(line + <span class="string">'\n'</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      feval.write(line + <span class="string">'\n'</span>)</span><br><span class="line"></span><br><span class="line">fenroll.close()</span><br><span class="line">feval.close()</span><br></pre></td></tr></table></figure><p>这个脚本首先先将每个spk和与其对应的utt存入dictutt中，然后再将spk的utt顺序随机打乱，重新分配到enroll（注册集）和eval（评估集）中。可以看到在程序的倒数第六行中，if(i&lt;3):就将utt写入enroll中，否则就写入eval中。所以我们可以通过改这个值来改变注册集和评估集中的语音数。</p><p>在重新生成完utt2spk之后，就要生成trials了。trials通过loacl/product_trials.py来生成。trials是指需要进行打分的注册说话人和不同的语音的一个列表，它的格式为(举个例子🌰）：</p><table><thead><tr><th>uttID</th><th>spkID</th><th>target/nontarget</th></tr></thead><tbody><tr><td>spkA-utt1</td><td>spkA</td><td>target</td></tr><tr><td>spkA-utt2</td><td>spkB</td><td>nontarget</td></tr><tr><td>spkB-utt1</td><td>spkA</td><td>nontarget</td></tr><tr><td>spkB-utt1</td><td>spkB</td><td>target</td></tr><tr><td>…</td><td>…</td><td>…</td></tr></tbody></table><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#extract enroll ivector</span></span><br><span class="line">sid/extract_ivectors.sh --cmd <span class="string">"<span class="variable">$train_cmd</span>"</span> --nj 10 \</span><br><span class="line">  exp/extractor_1024 data/<span class="built_in">test</span>/enroll  exp/ivector_enroll_1024</span><br><span class="line"><span class="comment">#extract eval ivector</span></span><br><span class="line">sid/extract_ivectors.sh --cmd <span class="string">"<span class="variable">$train_cmd</span>"</span> --nj 10 \</span><br><span class="line">  exp/extractor_1024 data/<span class="built_in">test</span>/<span class="built_in">eval</span>  exp/ivector_eval_1024</span><br><span class="line"></span><br><span class="line"><span class="comment">#compute plda score</span></span><br><span class="line"><span class="variable">$train_cmd</span> exp/ivector_eval_1024/<span class="built_in">log</span>/plda_score.log \</span><br><span class="line">  ivector-plda-scoring --num-utts=ark:exp/ivector_enroll_1024/num_utts.ark \</span><br><span class="line">  exp/ivector_train_1024/plda \</span><br><span class="line">  ark:exp/ivector_enroll_1024/spk_ivector.ark \</span><br><span class="line">  <span class="string">"ark:ivector-normalize-length scp:exp/ivector_eval_1024/ivector.scp ark:- |"</span> \</span><br><span class="line">  <span class="string">"cat '<span class="variable">$trials</span>' | awk '&#123;print \\\$2, \\\$1&#125;' |"</span> exp/trials_out</span><br><span class="line"></span><br><span class="line"><span class="comment">#compute eer</span></span><br><span class="line">awk <span class="string">'&#123;print $3&#125;'</span> exp/trials_out | paste - <span class="variable">$trials</span> | awk <span class="string">'&#123;print $1, $4&#125;'</span> | compute-eer -</span><br></pre></td></tr></table></figure><p>在将测试集分成注册集和评估集之后，就开始分别提取注册集和评估集的ivector，然后按照生成的trials打分，最终打分结果输出在trials_out中,最终跑出来的结果为eer为0.183%。</p><h2 id="使用TIMIT数据库进行声纹识别"><a href="#使用TIMIT数据库进行声纹识别" class="headerlink" title="使用TIMIT数据库进行声纹识别"></a>使用TIMIT数据库进行声纹识别</h2><p>在了解了kaldi中整个声纹识别的流程后，我们就可以AISHELL的例程来改写使用自己数据的声纹识别系统，这里我使用TIMIT数据库。</p><p>我们首先看下AISHELL和TIMIT数据库中的数据划分。AISHELL中一共有400人，默认分为train、dev和test集。其中train里面有340人；dev里面有40人；test里面有20人。在例程中，使用train作为训练集，test作为测试集，并没有使用dev。AISHELL里每个人大概有300多段语音，每段语音是一句话，每段语音大概在2~6s。在TIMIT数据库中一共有630人，分为train和test。训练集中有462人，测试集中有168人。每个人分别有10段语音，每段语音大概在2~4s。这里就直接使用TIMIT的原本的分配方式，用462人作为训练集，168人作为测试集。</p><p>不过使用TIMIT数据库还有一个问题就是，TIMIT数据库中文件存放以及命名的方式和AISHELL不太一样。TIMIT数据库下文件存放的结构是，/TRAIN/DR<em>/SPEARKER_ID/UTTERANCE_ID.wav，train代表是训练集或者测试集，DR\</em>（1～8）代表了说话人的方言类型，然后是说话人的ID文件夹，文件夹下存放了10段语音。TIMIT数据库中不同的人会说同一段话，说的话的内容是一样的话文件名就是一样的，我不知道如果有相同的文件名会不会引发错误，稳妥起见还是把每个文件都重新命名了。我写了个程序，将文件都重新命名为说话人的ID加上音频的序号，并且将其重新保存在/TRAIN/SPEAKER_ID这样的目录下，这样就在下面的程序就可以不用修改太多。</p><p>在了解完两个数据库的区别和整个声纹识别的流程之后，我们就可以开始改写我们的程序了。其实整个过程中需要改的地方并不多，主要就是在准备数据阶段和生成trials的过程需要修改一下。首先是数据准备阶段，我们就可以根据哈aishell_data_prepare.sh这个脚本来改写自己的timit_data_prepare.sh了。数据准备阶段就要生成utt2spk spk2utt和wav.scp这三个文件。这三个文件的格式如下：</p><table><thead><tr><th>文件名</th><th>格式</th></tr></thead><tbody><tr><td>utt2spk</td><td>[音频文件名] [说话人ID]</td></tr><tr><td>spk2utt</td><td>[说话人名] [音频文件名] [音频文件名] [音频文件名]</td></tr><tr><td>wav.scp</td><td>[音频文件名] [音频文件的具体路径]</td></tr></tbody></table><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">. ./path.sh || <span class="built_in">exit</span> 1;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$#</span> != 2 ]; <span class="keyword">then</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="string">"Usage: <span class="variable">$0</span> &lt;audio-path&gt; &lt;text-path&gt;"</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="string">" <span class="variable">$0</span> /export/a05/xna/data/data_aishell/wav /export/a05/xna/data/data_aishell/transcript"</span></span><br><span class="line">  <span class="built_in">exit</span> 1;</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">aishell_audio_dir=<span class="variable">$1</span></span><br><span class="line">aishell_text_dir=<span class="variable">$2</span></span><br><span class="line"></span><br><span class="line">train_dir=data/<span class="built_in">local</span>/train</span><br><span class="line">dev_dir=data/<span class="built_in">local</span>/dev</span><br><span class="line">test_dir=data/<span class="built_in">local</span>/<span class="built_in">test</span></span><br><span class="line"></span><br><span class="line">mkdir -p <span class="variable">$train_dir</span></span><br><span class="line">mkdir -p <span class="variable">$dev_dir</span></span><br><span class="line">mkdir -p <span class="variable">$test_dir</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># data directory check</span></span><br><span class="line"><span class="keyword">if</span> [ ! -d <span class="variable">$aishell_audio_dir</span> ] || [ ! -d <span class="variable">$aishell_text_dir</span> ]; <span class="keyword">then</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="string">"Error: <span class="variable">$0</span> requires two directory arguments"</span></span><br><span class="line">  <span class="built_in">exit</span> 1;</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># find wav audio file for train, dev and test resp.</span></span><br><span class="line">find <span class="variable">$aishell_audio_dir</span> -iname <span class="string">"*.wav"</span> | grep -i <span class="string">"wav/train"</span> &gt; <span class="variable">$train_dir</span>/wav.flist || <span class="built_in">exit</span> 1;</span><br><span class="line">find <span class="variable">$aishell_audio_dir</span> -iname <span class="string">"*.wav"</span> | grep -i <span class="string">"wav/dev"</span> &gt; <span class="variable">$dev_dir</span>/wav.flist || <span class="built_in">exit</span> 1;</span><br><span class="line">find <span class="variable">$aishell_audio_dir</span> -iname <span class="string">"*.wav"</span> | grep -i <span class="string">"wav/test"</span> &gt; <span class="variable">$test_dir</span>/wav.flist || <span class="built_in">exit</span> 1;</span><br></pre></td></tr></table></figure><p>前面首先是检查路径和创建用来存放文件的路径，由于在TIMIT中没有dev集，所以要把带有dev的都删掉。接下来脚本查找目录下的所有wav文件。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">n=`cat <span class="variable">$train_dir</span>/wav.flist <span class="variable">$dev_dir</span>/wav.flist <span class="variable">$test_dir</span>/wav.flist | wc -l`</span><br><span class="line">[ <span class="variable">$n</span> -ne 141925 ] &amp;&amp; \</span><br><span class="line">  <span class="built_in">echo</span> Warning: expected 141925 data data files, found <span class="variable">$n</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Transcriptions preparation</span></span><br><span class="line"><span class="keyword">for</span> dir <span class="keyword">in</span> <span class="variable">$train_dir</span> <span class="variable">$test_dir</span>; <span class="keyword">do</span></span><br><span class="line">  <span class="built_in">echo</span> Preparing <span class="variable">$dir</span> transcriptions</span><br><span class="line">  sed -e <span class="string">'s/\.wav//'</span> <span class="variable">$dir</span>/wav.flist | awk -F <span class="string">'/'</span> <span class="string">'&#123;print $NF&#125;'</span> &gt; <span class="variable">$dir</span>/utt.list</span><br><span class="line">  sed -e <span class="string">'s/\.wav//'</span> <span class="variable">$dir</span>/wav.flist | awk -F <span class="string">'/'</span> <span class="string">'&#123;i=NF-1;printf("%s %s\n",$NF,$i)&#125;'</span> &gt; <span class="variable">$dir</span>/utt2spk_all</span><br><span class="line">  paste -d<span class="string">' '</span> <span class="variable">$dir</span>/utt.list <span class="variable">$dir</span>/wav.flist &gt; <span class="variable">$dir</span>/wav.scp_all</span><br><span class="line">  utils/filter_scp.pl -f 1 <span class="variable">$dir</span>/utt.list <span class="variable">$aishell_text_dir</span>/*.txt &gt; <span class="variable">$dir</span>/transcripts.txt</span><br><span class="line">  awk <span class="string">'&#123;print $1&#125;'</span> <span class="variable">$dir</span>/transcripts.txt | sort -u &gt; <span class="variable">$dir</span>/utt.list</span><br><span class="line">  utils/filter_scp.pl -f 1 <span class="variable">$dir</span>/utt.list <span class="variable">$dir</span>/utt2spk_all | sort -u &gt; <span class="variable">$dir</span>/utt2spk</span><br><span class="line">  utils/filter_scp.pl -f 1 <span class="variable">$dir</span>/utt.list <span class="variable">$dir</span>/wav.scp_all | sort -u &gt; <span class="variable">$dir</span>/wav.scp</span><br><span class="line">  sort -u <span class="variable">$dir</span>/transcripts.txt &gt; <span class="variable">$dir</span>/text</span><br><span class="line">  utils/utt2spk_to_spk2utt.pl <span class="variable">$dir</span>/utt2spk &gt; <span class="variable">$dir</span>/spk2utt</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line">mkdir -p data/train data/<span class="built_in">test</span></span><br><span class="line"><span class="keyword">for</span> f <span class="keyword">in</span> spk2utt utt2spk wav.scp text; <span class="keyword">do</span></span><br><span class="line">  cp <span class="variable">$train_dir</span>/<span class="variable">$f</span> data/train/<span class="variable">$f</span> || <span class="built_in">exit</span> 1;</span><br><span class="line">  cp <span class="variable">$test_dir</span>/<span class="variable">$f</span> data/<span class="built_in">test</span>/<span class="variable">$f</span> || <span class="built_in">exit</span> 1;</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"<span class="variable">$0</span>: AISHELL data preparation succeeded"</span></span><br><span class="line"><span class="built_in">exit</span> 0;</span><br></pre></td></tr></table></figure><p>接下来就检查找到的wav文件加起来有没有141924个，然后就开始做wav.scp、utt2spk和spk2utt以及用于语音识别的transcripts.txt，这里我们就要找到脚本中和transcripts.txt相关的，然后删掉就可以了。</p><p>再做完准备数据的阶段之后，我们就可以开始按照上面的流程来进行声纹识别了。还需要注意的一点是trials，如果一个人只有两三段语音的话，就需要修改分配enroll集和eval集的比例。不过由于TIMIT数据库每个人有10段语音，所以不用修改也是可以的。这里就用3段语音去注册，然后剩下的7段语音用于验证。</p><p>最终跑出来的等错误率在4.5%左右，虽然是一个还可以接受的结果，但是和AISHELL的0.18%的等错误率相比还是差了很多的。分析一下原因：首先是用于训练的语音较少，虽然人数有462人，但是每个人只有10段语音，和AISHELL中340人用于训练，每个人300多段语音相比差了很多。同样的，TIMIT中测试集中一共有168人，相比于AISHELL中测试集只有40人多了很多。而且，AISHELL默认的训练的UBM阶数和ivector的维度都非常高，所以这两点可能导致了等错误率比较高。如果想进一步降低等错误率可以尝试降低训练的UBM和ivector的维度。我把UBM和ivector的维度都降低后，等错误率最终可以达到1.53%。</p><h2 id="kaldi中声纹识别的流程"><a href="#kaldi中声纹识别的流程" class="headerlink" title="kaldi中声纹识别的流程"></a>kaldi中声纹识别的流程</h2><p>总结一下，kaldi中声纹的识别（ivector）的流程图如下：</p><p><img src="/upload_image/2.png" alt=""></p><p>首先，将数据集分为训练集和测试集。然后对先对训练集做处理，先提取训练集的mfcc特征，然后训练UBM和ivector extractor，接着提取训练集的ivector，并使用训练集的ivector去训练plda模型。之后就开始对测试集进行处理，先把测试集分为注册集和验证集，分别提取mfcc然后在提取ivector，在用plda进行打分。这就是整个kaldi中ivector声纹识别的流程了。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;前段时间一直到在使用kaldi来做声纹识别，算是可以把整个ivector的例程可以跑下来，也可以根据例程来改写脚本，使用自己的数据来训练和测试。接下来可能要去做其他的项目了，所以要趁着还记得的时候赶紧写个总结，也算是对之前的工作也算是归纳一下。&lt;br&gt;
    
    </summary>
    
      <category term="声纹识别" scheme="http://yutouwd.github.io/categories/%E5%A3%B0%E7%BA%B9%E8%AF%86%E5%88%AB/"/>
    
    
      <category term="kaldi" scheme="http://yutouwd.github.io/tags/kaldi/"/>
    
      <category term="声纹识别" scheme="http://yutouwd.github.io/tags/%E5%A3%B0%E7%BA%B9%E8%AF%86%E5%88%AB/"/>
    
      <category term="ivector" scheme="http://yutouwd.github.io/tags/ivector/"/>
    
  </entry>
  
</feed>
